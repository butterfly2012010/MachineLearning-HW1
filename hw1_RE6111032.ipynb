{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    # 處理 data.csv\n",
    "    # 用pandas讀資料，處理後再分開X和Y\n",
    "    def data_prepare_1(self, file_path):\n",
    "        df_file = pd.read_csv(file_path)\n",
    "        Y = df_file['Diagnosis'].map({'M':-1, 'B':1}).to_numpy()      \n",
    "        X = df_file.iloc[:,2:].to_numpy()\n",
    "        return X, Y\n",
    "\n",
    "    # 處理 crx.csv\n",
    "    def data_prepare_2(self, file_path):\n",
    "        df_file = pd.read_csv(file_path)\n",
    "        Y = df_file['label'].map({'+':1, '-':-1}).to_numpy()\n",
    "        X = df_file.iloc[:,:15]\n",
    "        X['att1'] = X['att1'].map({'?':0, 'a':-1, 'b':1})\n",
    "        X['att2'] = X['att2'].replace('?', 0)\n",
    "        X['att2'] = X['att2'].astype(float)\n",
    "        X['att4'] = X['att4'].map({'?':0, 'u':-1, 'y':1, 'l':2})\n",
    "        X['att5'] = X['att5'].map({'?':0, 'g':-1, 'p':1, 'gg':2})\n",
    "        X['att6'] = X['att6'].map({'?':0, 'c':-7, 'q':-6, 'w':-5, 'i':-4, 'aa':-3,\n",
    "                        'ff':-2, 'k':-1, 'cc':1, 'm':2, 'x':3, 'd':4,\n",
    "                        'e':5, 'j':6, 'r':7})\n",
    "        X['att7'] = X['att7'].map({'?':0, 'v':-4, 'h':-3, 'bb':-2, 'ff':-1, 'j':1,\n",
    "                        'z':2, 'dd':3, 'n':4, 'o':5})\n",
    "        X['att9'] = X['att9'].map({'t':-1, 'f':1})\n",
    "        X['att10'] = X['att10'].map({'t':-1, 'f':1})\n",
    "        X['att12'] = X['att12'].map({'t':-1, 'f':1})\n",
    "        X['att13'] = X['att13'].map({'g':0, 's':-1, 'p':1})\n",
    "        X['att14'] = X['att14'].replace('?', 0)\n",
    "        X['att14'] = X['att14'].astype(float)\n",
    "        X = X.to_numpy()\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.acc1 = 0\n",
    "        self.acc2 = 0\n",
    "    '''\n",
    "    2. Please implement the Linear Classifier from scratch with the update rule in the slide.\n",
    "    It means you cannot adopt any existing package like sklearn in this assignment. \n",
    "    '''\n",
    "    def LinearClassifier(self, X, Y):\n",
    "        # 收斂:全部分類正確或是while迴圈次數大於1000次\n",
    "        convergenceFlag = False\n",
    "        convergenceNumbers = 0\n",
    "        iterations = 0\n",
    "        # learning rate\n",
    "        lr = 0.001\n",
    "        # array of number for shuffling\n",
    "        order = np.arange(0,len(X),1)\n",
    "\n",
    "        random.seed(1)\n",
    "        W = np.random.rand(X.shape[1])\n",
    "        b = np.random.random()\n",
    "\n",
    "        start_time = time.time()\n",
    "        while not convergenceFlag:\n",
    "            iterations += 1\n",
    "            \n",
    "            random.shuffle(order)\n",
    "            for i in order:\n",
    "                # F = X[i,:].reshape((len(X[i,:])))\n",
    "                F = X[i,:]\n",
    "                label = Y[i]\n",
    "                # check if it's correct based on the current model\n",
    "                prediction = 1 if (np.dot(W, F) + b) > 0 else -1\n",
    "\n",
    "                if label * prediction < 0:\n",
    "                    # update all the weights\n",
    "                    for j in range(len(W)):\n",
    "                        W[j] = W[j] + lr * (F[j] * label)\n",
    "                    b = b + label\n",
    "                else:\n",
    "                    convergenceNumbers += 1\n",
    "\n",
    "            if iterations > 1000 or convergenceNumbers == len(Y):\n",
    "                convergenceFlag = True\n",
    "\n",
    "        print('--- {} seconds ---'.format(time.time() - start_time))\n",
    "        print('--- ||w||^2: {} ---'.format(np.linalg.norm(W)**2))\n",
    "\n",
    "        # calculate the correction number (accuracy)\n",
    "        s = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            pred = 1 if (np.dot(W, x) + b) > 0 else -1\n",
    "            if y == pred:\n",
    "                s += 1\n",
    "        self.acc1 = s / len(Y)\n",
    "        print('--- accuracy: {} ---'.format(self.acc1))\n",
    "    '''\n",
    "    3. When the \"J=WX+b\" could be represented as the matrix form for the linear classifier,\n",
    "    please find the solution by solving this equation using least-squared manner.\n",
    "    Also, please implement it and make a comparison between this method and the previous one implemented in 2.\n",
    "    '''\n",
    "    def LinearClassifierMatrixForm(self, X, Y):\n",
    "        Y = Y.reshape((len(Y), 1))\n",
    "        W = np.ones((X.shape[1], 1))\n",
    "        b = np.random.random()\n",
    "\n",
    "        start_time = time.time()\n",
    "        # check if it's correct based on the current model\n",
    "        beta_hat = np.vstack((b, W))\n",
    "        designMatrix = np.hstack((np.ones((len(X), 1)), X))\n",
    "        \n",
    "        # update all the weights by least squared method\n",
    "        beta_hat = np.linalg.inv(designMatrix.T @ designMatrix) @ designMatrix.T @ Y\n",
    "\n",
    "        print('--- {} seconds ---'.format(time.time() - start_time))\n",
    "        print('--- ||w||^2: {} ---'.format(np.linalg.norm(beta_hat[1:])**2))\n",
    "\n",
    "        # calculate the correction number (accuracy)\n",
    "        s = 0\n",
    "        preds = [1 if item > 0 else -1 for item in (np.dot(designMatrix, beta_hat))]\n",
    "        for y, pred in zip(Y, preds):\n",
    "            if y == pred:\n",
    "                s += 1\n",
    "        self.acc2 = s / len(Y)\n",
    "        print('--- accuracy: {} ---'.format(self.acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voted Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotedPerceptron:\n",
    "    def __init__(self, n_iter) -> None:\n",
    "        self.n_iter = n_iter\n",
    "        self.W = [] # store the weights\n",
    "        self.C = [] # store the number of examples that set of weights got correct\n",
    "        self.B = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        w = [np.ones_like(x[0])] # store the weights\n",
    "        b = [0]\n",
    "        c = [0] # store the number of examples that set of weights got correct\n",
    "        k = 0\n",
    "        # learning rate\n",
    "        lr = 0.001\n",
    "\n",
    "        # train n_iter epochs\n",
    "        for epoch in range(self.n_iter):\n",
    "            # check if each x_i is classified right\n",
    "            for i in range(len(x)):\n",
    "                pred = 1 if np.dot(w[k], x[i]) + b[k] > 0 else -1 # checks the sign of w*k\n",
    "                if pred == y[i]: # checks if the prediction matches the real Y\n",
    "                    c[k] += 1 # increments c\n",
    "                else:\n",
    "                    w.append(np.add(w[k], lr * y[i] * x[i]))\n",
    "                    b.append(np.add(b[k], y[i]))\n",
    "                    c.append(0)\n",
    "                    k += 1\n",
    "\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.C = c\n",
    "        self.k = k\n",
    "\n",
    "    def predict(self, X):\n",
    "        # calculate the prediction from ALL saved weights\n",
    "        # multiply each prediction by the number it got correct (i.e a weighted vote) and take the sum over all predictions\n",
    "        # said another way: pick whichever prediction has the most votes\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            s = 0\n",
    "            for w, b, c in zip(self.W, self.B, self.C):\n",
    "                s = s + c * (np.dot(w, x) + b)\n",
    "            preds.append(np.sign(1 if s >= 0 else -1))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self) -> None:\n",
    "        self.acc1 = 0\n",
    "        self.acc2 = 0\n",
    "    '''\n",
    "    5. With minimizing the ||w||^2, it should drive the marginal to be maximized as well.\n",
    "    Please implement the linear classifier with the minimum ||w||^2 property and verify\n",
    "    whether the margin of this version is larger than that of the conventional linear classifier or not. \n",
    "    '''\n",
    "    def SVM(self, X, Y):\n",
    "        # objective function: ||w||^2\n",
    "        # gradient descent\n",
    "        # constraint: y(wx+b)>=1\n",
    "\n",
    "        Y = Y.reshape((len(Y), 1))\n",
    "        w = np.ones_like(X[0])\n",
    "        b = np.random.random()\n",
    "        # learning rate\n",
    "        lr = 0.01\n",
    "\n",
    "        iter = 0\n",
    "        start_time = time.time()\n",
    "        while iter < 100:\n",
    "            for i in range(len(X)):\n",
    "                \"\"\"\n",
    "                Cost Function:\n",
    "                    l(w) = sum(max(0, 1 - y(wX + b))) + (lambda/2)(||w||)^2\n",
    "                    First Term is Hinge Loss, Second is Regularization term\n",
    "                Gradient:\n",
    "                    delta_w = dl/dw = (1/n) * ( if y(wX+b) < 1: -yX + lambda*w else: lambda*w )\n",
    "                Gradient Descent\n",
    "                    w = w - (learning_rate * delta_w)\n",
    "\t\t        \"\"\"\n",
    "                pred = 1 if (np.dot(w, X[i]) + b) > 0 else -1\n",
    "                loss = np.linalg.norm(w, ord=2)**2\n",
    "                delta = 1e-4\n",
    "                if pred * Y[i] < 1:\n",
    "                    for j in range(len(w)):\n",
    "                        w[j] -= lr * (-Y[i] * X[i,j]) * delta\n",
    "                    b = b + Y[i]\n",
    "            \n",
    "            iter += 1\n",
    "\n",
    "        print('--- {} seconds ---'.format(time.time() - start_time))\n",
    "        print('--- ||w||^2: {} ---'.format(np.linalg.norm(w)**2))\n",
    "\n",
    "        # calculate the correction number (accuracy)\n",
    "        s = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            pred = 1 if (np.dot(w, x) + b) > 0 else -1\n",
    "            if y == pred:\n",
    "                s += 1\n",
    "        self.acc1 = s / len(Y)\n",
    "        print('--- accuracy: {} ---'.format(self.acc1))\n",
    "\n",
    "    '''\n",
    "    6. Based on 5, please add the slack variable term in the linear classifier and find the most effective weighting value C.\n",
    "    '''\n",
    "    def SVM2(self, X, Y):\n",
    "        # objective function: ||w||^2\n",
    "        # gradient descent\n",
    "        # constraint: y(wx+b)>=1\n",
    "        # with slack variables\n",
    "\n",
    "        Y = Y.reshape((len(Y), 1))\n",
    "        w = np.ones_like(X[0])\n",
    "        b = np.random.random()\n",
    "        # learning rate\n",
    "        lr = 0.01\n",
    "        # constant of slack variables\n",
    "        C = 0.1\n",
    "        # slack variables\n",
    "        slackVariables = np.zeros(len(X))\n",
    "\n",
    "        iter = 0\n",
    "        start_time = time.time()\n",
    "        while iter < 100:\n",
    "            for i in range(len(X)):\n",
    "                pred = 1 if (np.dot(w, X[i]) + b) >= 0 else -1\n",
    "\n",
    "                # compute slack variables\n",
    "                for k in range(len(X)):\n",
    "                    pred = 1 if (np.dot(w, X[k]) + b) >= 0 else -1\n",
    "                    slackVariables[i] == max(0, 1 - Y[i] * pred)\n",
    "\n",
    "                loss = np.linalg.norm(w, ord=2)**2 + C * np.sum(slackVariables)\n",
    "                delta = 1e-4\n",
    "                if pred * Y[i] < 1:\n",
    "                    # first_order_loss = np.array([2 * w[j] + C * np.dot(X[:,j], Y) for j in range(len(w))]).reshape(len(X[0])) # gradient of loss\n",
    "                    # w = w - lr * first_order_loss\n",
    "                    for j in range(len(w)):\n",
    "                        w[j] -= lr * (-Y[i] * X[i,j]) * delta\n",
    "                    b = b + Y[i]\n",
    "\n",
    "            iter += 1\n",
    "\n",
    "        print('--- {} seconds ---'.format(time.time() - start_time))\n",
    "        print('--- ||w||^2: {} ---'.format(np.linalg.norm(w)**2))\n",
    "\n",
    "        # calculate the correction number (accuracy)\n",
    "        s = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            pred = 1 if (np.dot(w, x) + b) >= 0 else -1\n",
    "            if y == pred:\n",
    "                s += 1\n",
    "        self.acc2 = s / len(Y)\n",
    "        print('--- accuracy: {} ---'.format(self.acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data.csv'\n",
    "X, Y = DataPreprocess().data_prepare_1(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.9354827404022217 seconds ---\n",
      "--- ||w||^2: 4364.791920036971 ---\n",
      "--- accuracy: 0.9191564147627417 ---\n"
     ]
    }
   ],
   "source": [
    "classifier.LinearClassifier(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Classifier with Matrix Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.001001596450805664 seconds ---\n",
      "--- ||w||^2: 1895.4506394416992 ---\n",
      "--- accuracy: 0.9648506151142355 ---\n"
     ]
    }
   ],
   "source": [
    "classifier.LinearClassifierMatrixForm(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Voted Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "v_perc = VotedPerceptron(n_iter=100)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "v_perc.fit(X_train, Y_train)\n",
    "Ypred = v_perc.predict(X_test)\n",
    "# Y_tolist = Y.tolist()\n",
    "print('Accuracy score: ', accuracy_score(Y_test, Ypred))\n",
    "# print('Metrics Report')\n",
    "# print(classification_report(Y_tolist, Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without Slack Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7730846405029297 seconds ---\n",
      "--- ||w||^2: 27.27858511144094 ---\n",
      "--- accuracy: 0.8787346221441125 ---\n"
     ]
    }
   ],
   "source": [
    "svm.SVM(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Slack Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 392.202011346817 seconds ---\n",
      "--- ||w||^2: 80.37248564241975 ---\n",
      "--- accuracy: 0.38488576449912126 ---\n"
     ]
    }
   ],
   "source": [
    "svm.SVM2(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Any Existing SVM Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "clf = sklearn.svm.SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"crx.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './crx.csv'\n",
    "X, Y = DataPreprocess().data_prepare_2(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.8493974208831787 seconds ---\n",
      "--- ||w||^2: 17035.660831605295 ---\n",
      "--- accuracy: 0.6666666666666666 ---\n"
     ]
    }
   ],
   "source": [
    "classifier.LinearClassifier(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Classifier with Matrix Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0009999275207519531 seconds ---\n",
      "--- ||w||^2: 3.4659748636273007e+33 ---\n",
      "--- accuracy: 0.5260869565217391 ---\n"
     ]
    }
   ],
   "source": [
    "classifier.LinearClassifierMatrixForm(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Voted Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6936416184971098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "v_perc = VotedPerceptron(n_iter=100)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "v_perc.fit(X_train, Y_train)\n",
    "Ypred = v_perc.predict(X_test)\n",
    "# Y_tolist = Y.tolist()\n",
    "print('Accuracy score: ', accuracy_score(Y_test, Ypred))\n",
    "# print('Metrics Report')\n",
    "# print(classification_report(Y_tolist, Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without Slack Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.9575891494750977 seconds ---\n",
      "--- ||w||^2: 12.722853592062004 ---\n",
      "--- accuracy: 0.663768115942029 ---\n"
     ]
    }
   ],
   "source": [
    "svm.SVM(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Slack Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 356.1844391822815 seconds ---\n",
      "--- ||w||^2: 156.49774122955563 ---\n",
      "--- accuracy: 0.4449275362318841 ---\n"
     ]
    }
   ],
   "source": [
    "svm.SVM2(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Any Existing SVM Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167630057803468"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "clf = sklearn.svm.SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
